{
  "paragraphs": [
    {
      "title": "Temp set-up",
      "text": "%pyspark\n\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as f\nfrom pyspark.sql import *\n\n# number of buckets for our platform\nNUM_BUCKETS \u003d 2048\n\nspark \u003d SparkSession.builder.getOrCreate()\n\n# root data store path: TODO change this to the official one when established.\ndata_store \u003d \"file:////data/gaia/\"  # \"file:////user/nch/PARQUET/REPARTITIONED/\"\n\n# default key by which to bucket and sort: Gaia catalogue source UID \ndefault_key \u003d \"source_id\"\n\n# Save a dataframe to a set of bucketed parquet files, repartitioning beforehand and sorting (by default by source UID) within the buckets:\ndef saveToBinnedParquet(df, outputParquetPath, name, mode \u003d \"error\", buckets \u003d NUM_BUCKETS, bucket_and_sort_key \u003d default_key):\n    \u0027\u0027\u0027\n    Save a data frame to a set of bucketed parquet files, repartitioning beforehand and sorting\n    (by default on DPAC Gaia source UID) within the buckets.\n    \n    Parameters\n    ----------\n    df : DataFrame\n        (mandatory) the data frame to be written to the persistent file store\n    outputParquetPath : str\n        (mandatory) the absolute path name of the folder to contain the files\n    mode : str\n        (optional) the mode for the underlying DataFrame write method (default : error, i.e. no silent failures)\n    buckets : int\n        (optional) the number of buckets (if in doubt leave as the default)\n    bucket_and_sort_key : str\n        (optional) the bucketing and sorting key for the keyed/clustered data (default source_id; you must specify\n        an alternative if the data frame does not have this column present)\n    \u0027\u0027\u0027\n    df \u003d df.repartition(buckets, bucket_and_sort_key)\n    df.write.format(\"parquet\") \\\n            .mode(mode) \\\n            .bucketBy(buckets, bucket_and_sort_key) \\\n            .sortBy(bucket_and_sort_key) \\\n            .option(\"path\", outputParquetPath) \\\n            .saveAsTable(name)\n\ndef reattachParquetFileResourceToSparkContext(table_name, file_path, schema_structures, cluster_key \u003d default_key, sort_key \u003d default_key, buckets \u003d NUM_BUCKETS):\n\t\"\"\"\n\tCreates a Spark (in-memory) meta-record for the table resource specified for querying\n\tthrough the PySpark SQL API.\n\tDefault assumption is that the table contains the Gaia source_id attribute and that the files have\n\tbeen previously partitioned, bucketed and sorted on this field in parquet format\n\t- see function saveToBinnedParquet().  If the table name specified already exists in the\n\tcatalogue IT WILL BE REMOVED (but the underlying data, assumed external, will remain).\n\tParameters\n\t----------\n\ttable_name : str\n\t\tThe table name to be used as the identifier in SQL queries etc.\n\tfile_path : str\n\t\tThe full disk file system path name to the folder containing the parquet file set.\n\tschema_structures : StructType\n\t\tOne or more schema structures expressed as a StructType object containing a list of\n\t\tStructField(field_name : str, type : data_type : DataType(), nullable : boolean)\n\tcluster_key : str (optional)\n\t    The clustering key (\u003d bucketing and sort key) in the partitioned data set on disk. \n\t    Default is Gaia catalogue source UID (\u003d source_id).\n\tsort_key : str (optional)\n\t    The sorting key within buckets in the partitioned data set on disk. \n\t    Default is Gaia catalogue source UID (\u003d source_id).\n\tbuckets : int (optional)\n\t    Number of buckets into which the data is organised.\n\t\"\"\"\n\n\t# put in the columns and their data types ...\n\ttable_create_statement \u003d \"CREATE TABLE `\" + table_name + \"` (\"\n\tfor schema_structure in schema_structures:\n\t\tfor field in schema_structure:\n\t\t\ttable_create_statement +\u003d \"`\" + field.name + \"` \" + field.dataType.simpleString() + \",\"\n\t# ... zapping that extraneous comma at the end\n\ttable_create_statement \u003d table_create_statement[:-1]\n\n\t# append the organisational details\n\ttable_create_statement +\u003d \") USING parquet OPTIONS (path \u0027\" + file_path + \"\u0027) \"\n\ttable_create_statement +\u003d \"CLUSTERED BY (%s) SORTED BY (%s) INTO %d\" % (\n\t\tcluster_key, sort_key, buckets) + \" BUCKETS\"\n\n\n\t# scrub any existing record - N.B. tables defined in this way are EXTERNAL, so this statement will not scrub\n\t# the underlying file data set. Also if the table doesn\u0027t exist, this will silently do nothing (no exception\n\t# will be thrown).\n\tspark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n\n\t# create the table resource\n\tspark.sql(table_create_statement)\n\nimport copy\n\ndef create_interim_schema_for_csv(schema_structure):\n    \u0027\u0027\u0027\n    Takes a schema StructType() and substitutes all array types as a string in order\n    to create a schema against which csv files can be read into an interim data frame\n    prior to conversion of the comma-separated string of numerical values into an array\n    of the appropriate numeric type.\n    \n    Parameters\n    ----------\n    schema_structure : StructType\n        the table schema containing array types \n        \n    Returns: StructType\n    -------------------\n    An edited version of the given schema with all ArrayType changed to StringType\n    \u0027\u0027\u0027\n    \n    # new interim structure\n    interim_structure \u003d StructType()\n    \n    # iterate over the schema, copying in everything and substituting strings for any arrays\n    for field in schema_structure:\n        interim_field \u003d copy.deepcopy(field)\n        if type(interim_field.dataType) \u003d\u003d ArrayType: interim_field.dataType \u003d StringType()\n        interim_structure.add(interim_field)\n    \n    return interim_structure\n\ndef cast_to_array(data_frame : DataFrame, column_name : str, data_type : DataType):\n    \"\"\"\n    Casts the specified string column in the given data frame into an\n    array with the specified data type. Assumes the string column contains\n    comma-separated values in plain text delimited by braces (which are\n    ignored). The array column is appended to the existing column set while \n    the original string column is removed. The resulting data frame will\n    contain an array column with the same name as the original string\n    data column.\n    \n    Parameters:\n    -----------\n    data_frame : DataFrame()\n        The PySpark data frame instance to be operated on\n    column_name : str\n        The column name that contains the array data as a plain text string of \n        comma-separated values\n    data_type : DataType()\n        The PySpark data structure data type which should be ArrayType(SomeType())\n        \n    Returns:\n    --------\n    a new data frame containing the requested modification\n    \"\"\"\n    \n    # a temporary working column name for the array\n    temporary_column_name \u003d column_name + \u0027_array_data\u0027\n    \n    # reformat the string csv data as an array of the specified type\n    data_frame \u003d data_frame.withColumn(temporary_column_name, f.split(f.col(column_name).substr(f.lit(2), f.length(f.col(column_name)) - 2), \u0027,\u0027).cast(data_type))\n    \n    # drop the original string column to save space\n    data_frame \u003d data_frame.drop(column_name)\n    \n    # rename the temporary column with the original column name\n    data_frame \u003d data_frame.withColumnRenamed(temporary_column_name, column_name)\n    \n    return data_frame\n    \n    \ndef reorder_columns(data_frame : DataFrame, data_structure : StructType):\n    \"\"\"\n    Reorder the columns according to the Gaia archive public schema and so that\n    the parquet files can be re-attached against that standard schema.\n    \n    Parameters:\n    -----------\n    data_frame : DataFrame()\n        The PySpark data frame instance to be operated on\n    data_structure : StructType()\n        The PySpark data structure containing the required schema definition\n    \"\"\"\n    \n    # use the schema to define the column order\n    ordered_columns \u003d [field.name for field in data_structure]\n    \n    # give it back in the schema-driven order\n    return data_frame.select(ordered_columns)\n    \n\ndef cast_all_arrays(data_frame : DataFrame, data_structure : StructType):\n    \"\"\"\n    Given an interim data frame read from csv and containing arrays in\n    plain text string representation, cycles over the schema transforming\n    all strings associated with arrays into the required primitive type.\n    \n    Parameters:\n    -----------\n    data_frame : DataFrame()\n        The PySpark data frame instance to be operated on\n    data_structure : StructType()\n        The PySpark data structure containing the required schema definition\n    \"\"\"\n    \n    # cycle over the defined fields looking for arrays\n    for field in data_structure:\n        \n        # if it\u0027s an array type then transmogrify:\n        if type(field.dataType) \u003d\u003d ArrayType: \n            data_frame \u003d cast_to_array(data_frame, field.name, field.dataType)\n    \n    # finally reorder according to the original specification\n    return reorder_columns(data_frame, data_structure)\n    ",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1527102755",
      "id": "paragraph_1656365002871_1020447808",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# check the available resources\nfor line in spark.catalog.listTables(): print (line)\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_318647911",
      "id": "paragraph_1656411704078_1018854894",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "Set up",
      "text": "%pyspark\n\n#from gaiadmpsetup import gaiadmpstore\n\n#from gaiadmpsetup import gaiadr3_pyspark_schema_structures as gdr3_schema\nfrom pyspark.sql.types import *\n\n# for the avoidance of confusion\nspark.sql(\u0027create database gaiadr3\u0027)\nspark.sql(\u0027use gaiadr3\u0027)\n\n# sanity check\n# print (gdr3_schema.gaia_source_schema)\n\n# SNAFU: boolean types expressed as strings \"True\", \"False\" in the CSVs but schema currently maps to bytes which throws exceptions. \n# Why not utilitse the appropriate PySpark BooleanType()? Try this:\ngaia_source_schema_test \u003d StructType([\n    StructField(\u0027solution_id\u0027, LongType(), True), # Solution Identifier\n    StructField(\u0027designation\u0027, StringType(), True), # Unique source designation (unique across all Data Releases)\n    StructField(\u0027source_id\u0027, LongType(), False), # Unique source identifier (unique within a particular Data Release)\n    StructField(\u0027random_index\u0027, LongType(), True), # Random index for use when selecting subsets\n    StructField(\u0027ref_epoch\u0027, DoubleType(), True), # Reference epoch\n    StructField(\u0027ra\u0027, DoubleType(), True), # Right ascension\n    StructField(\u0027ra_error\u0027, FloatType(), True), # Standard error of right ascension\n    StructField(\u0027dec\u0027, DoubleType(), True), # Declination\n    StructField(\u0027dec_error\u0027, FloatType(), True), # Standard error of declination\n    StructField(\u0027parallax\u0027, DoubleType(), True), # Parallax\n    StructField(\u0027parallax_error\u0027, FloatType(), True), # Standard error of parallax\n    StructField(\u0027parallax_over_error\u0027, FloatType(), True), # Parallax divided by its standard error\n    StructField(\u0027pm\u0027, FloatType(), True), # Total proper motion\n    StructField(\u0027pmra\u0027, DoubleType(), True), # Proper motion in right ascension direction\n    StructField(\u0027pmra_error\u0027, FloatType(), True), # Standard error of proper motion in right ascension direction\n    StructField(\u0027pmdec\u0027, DoubleType(), True), # Proper motion in declination direction\n    StructField(\u0027pmdec_error\u0027, FloatType(), True), # Standard error of proper motion in declination direction\n    StructField(\u0027ra_dec_corr\u0027, FloatType(), True), # Correlation between right ascension and declination\n    StructField(\u0027ra_parallax_corr\u0027, FloatType(), True), # Correlation between right ascension and parallax\t\t\n    StructField(\u0027ra_pmra_corr\u0027, FloatType(), True), # Correlation between right ascension and proper motion in right ascension\n    StructField(\u0027ra_pmdec_corr\u0027, FloatType(), True), # Correlation between right ascension and proper motion in declination\n    StructField(\u0027dec_parallax_corr\u0027, FloatType(), True), # Correlation between declination and parallax\n    StructField(\u0027dec_pmra_corr\u0027, FloatType(), True), # Correlation between declination and proper motion in right ascension\n    StructField(\u0027dec_pmdec_corr\u0027, FloatType(), True), # Correlation between declination and proper motion in declination\n    StructField(\u0027parallax_pmra_corr\u0027, FloatType(), True), # Correlation between parallax and proper motion in right ascension\n    StructField(\u0027parallax_pmdec_corr\u0027, FloatType(), True), # Correlation between parallax and proper motion in declination\n    StructField(\u0027pmra_pmdec_corr\u0027, FloatType(), True), # Correlation between proper motion in right ascension and proper motion in declination\n    StructField(\u0027astrometric_n_obs_al\u0027, ShortType(), True), # Total number of observations in the along-scan (AL) direction\n    StructField(\u0027astrometric_n_obs_ac\u0027, ShortType(), True), # Total number of observations in the across-scan (AC) direction\n    StructField(\u0027astrometric_n_good_obs_al\u0027, ShortType(), True), # Number of good observations in the along-scan (AL) direction\n    StructField(\u0027astrometric_n_bad_obs_al\u0027, ShortType(), True), # Number of bad observations in the along-scan (AL) direction\n    StructField(\u0027astrometric_gof_al\u0027, FloatType(), True), # Goodness of fit statistic of model wrt along-scan observations\n    StructField(\u0027astrometric_chi2_al\u0027, FloatType(), True), # AL chi-square value\n    StructField(\u0027astrometric_excess_noise\u0027, FloatType(), True), # Excess noise of the source\n    StructField(\u0027astrometric_excess_noise_sig\u0027, FloatType(), True), # Significance of excess noise\n    StructField(\u0027astrometric_params_solved\u0027, ByteType(), True), # Which parameters have been solved for?\n    StructField(\u0027astrometric_primary_flag\u0027, BooleanType(), True), # Primary or seconday\n    StructField(\u0027nu_eff_used_in_astrometry\u0027, FloatType(), True), # Effective wavenumber of the source used in the astrometric solution\n    StructField(\u0027pseudocolour\u0027, FloatType(), True), # Astrometrically estimated pseudocolour of the source\n    StructField(\u0027pseudocolour_error\u0027, FloatType(), True), # Standard error of the pseudocolour of the source\n    StructField(\u0027ra_pseudocolour_corr\u0027, FloatType(), True), # Correlation between right ascension and pseudocolour\n    StructField(\u0027dec_pseudocolour_corr\u0027, FloatType(), True), # Correlation between declination and pseudocolour\n    StructField(\u0027parallax_pseudocolour_corr\u0027, FloatType(), True), # Correlation between parallax and pseudocolour\n    StructField(\u0027pmra_pseudocolour_corr\u0027, FloatType(), True), # Correlation between proper motion in right asension and pseudocolour\n    StructField(\u0027pmdec_pseudocolour_corr\u0027, FloatType(), True), # Correlation between proper motion in declination and pseudocolour\n    StructField(\u0027astrometric_matched_transits\u0027, ShortType(), True), # Matched FOV transits used in the AGIS solution\n    StructField(\u0027visibility_periods_used\u0027, ShortType(), True), # Number of visibility periods used in Astrometric solution\n    StructField(\u0027astrometric_sigma5d_max\u0027, FloatType(), True), # The longest semi-major axis of the 5-d error ellipsoid\n    StructField(\u0027matched_transits\u0027, ShortType(), True), # The number of transits matched to this source\n    StructField(\u0027new_matched_transits\u0027, ShortType(), True), # The number of transits newly incorporated into an existing source in the current cycle\n    StructField(\u0027matched_transits_removed\u0027, ShortType(), True), # The number of transits removed from an existing source in the current cycle\n    StructField(\u0027ipd_gof_harmonic_amplitude\u0027, FloatType(), True), # Amplitude of the IPD GoF versus position angle of scan\n    StructField(\u0027ipd_gof_harmonic_phase\u0027, FloatType(), True), # Phase of the IPD GoF versus position angle of scan\n    StructField(\u0027ipd_frac_multi_peak\u0027, ByteType(), True), # Percent of successful-IPD windows with more than one peak\n    StructField(\u0027ipd_frac_odd_win\u0027, ByteType(), True), # Percent of transits with truncated windows or multiple gate\n    StructField(\u0027ruwe\u0027, FloatType(), True), # Renormalised unit weight error\n    StructField(\u0027scan_direction_strength_k1\u0027, FloatType(), True), # Degree of concentration of scan directions across the source\n    StructField(\u0027scan_direction_strength_k2\u0027, FloatType(), True), # Degree of concentration of scan directions across the source\n    StructField(\u0027scan_direction_strength_k3\u0027, FloatType(), True), # Degree of concentration of scan directions across the source\n    StructField(\u0027scan_direction_strength_k4\u0027, FloatType(), True), # Degree of concentration of scan directions across the source\n    StructField(\u0027scan_direction_mean_k1\u0027, FloatType(), True), # Mean position angle of scan directions across the source\n    StructField(\u0027scan_direction_mean_k2\u0027, FloatType(), True), # Mean position angle of scan directions across the source\n    StructField(\u0027scan_direction_mean_k3\u0027, FloatType(), True), # Mean position angle of scan directions across the source\n    StructField(\u0027scan_direction_mean_k4\u0027, FloatType(), True), # Mean position angle of scan directions across the source\n    StructField(\u0027duplicated_source\u0027, BooleanType(), True), # Source with multiple source identifiers\n    StructField(\u0027phot_g_n_obs\u0027, ShortType(), True), # Number of observations contributing to G photometry\n    StructField(\u0027phot_g_mean_flux\u0027, DoubleType(), True), # G-band mean flux\n    StructField(\u0027phot_g_mean_flux_error\u0027, FloatType(), True), # Error on G-band mean flux\n    StructField(\u0027phot_g_mean_flux_over_error\u0027, FloatType(), True), # G-band mean flux divided by its error\n    StructField(\u0027phot_g_mean_mag\u0027, FloatType(), True), # G-band mean magnitude\n    StructField(\u0027phot_bp_n_obs\u0027, ShortType(), True), # Number of observations contributing to BP photometry\n    StructField(\u0027phot_bp_mean_flux\u0027, DoubleType(), True), # Integrated BP mean flux\n    StructField(\u0027phot_bp_mean_flux_error\u0027, FloatType(), True), # Error on the integrated BP mean flux\n    StructField(\u0027phot_bp_mean_flux_over_error\u0027, FloatType(), True), # Integrated BP mean flux divided by its error\n    StructField(\u0027phot_bp_mean_mag\u0027, FloatType(), True), # Integrated BP mean magnitude\n    StructField(\u0027phot_rp_n_obs\u0027, ShortType(), True), # Number of observations contributing to RP photometry\n    StructField(\u0027phot_rp_mean_flux\u0027, DoubleType(), True), # Integrated RP mean flux\n    StructField(\u0027phot_rp_mean_flux_error\u0027, FloatType(), True), # Error on the integrated RP mean flux\n    StructField(\u0027phot_rp_mean_flux_over_error\u0027, FloatType(), True), # Integrated RP mean flux divided by its error\n    StructField(\u0027phot_rp_mean_mag\u0027, FloatType(), True), # Integrated RP mean magnitude\n    StructField(\u0027phot_bp_rp_excess_factor\u0027, FloatType(), True), # BP/RP excess factor\n    StructField(\u0027phot_bp_n_contaminated_transits\u0027, ShortType(), True), # Number of BP contaminated transits\n    StructField(\u0027phot_bp_n_blended_transits\u0027, ShortType(), True), # Number of BP blended transits\n    StructField(\u0027phot_rp_n_contaminated_transits\u0027, ShortType(), True), # Number of RP contaminated transits\n    StructField(\u0027phot_rp_n_blended_transits\u0027, ShortType(), True), # Number of RP blended transits\n    StructField(\u0027phot_proc_mode\u0027, ByteType(), True), # Photometry processing mode\n    StructField(\u0027bp_rp\u0027, FloatType(), True), # BP - RP colour\n    StructField(\u0027bp_g\u0027, FloatType(), True), # BP - G colour\n    StructField(\u0027g_rp\u0027, FloatType(), True), # G - RP colour\n    StructField(\u0027radial_velocity\u0027, FloatType(), True), # Radial velocity \n    StructField(\u0027radial_velocity_error\u0027, FloatType(), True), # Radial velocity error \n    StructField(\u0027rv_method_used\u0027, ByteType(), True), # Method used to obtain the radial velocity\n    StructField(\u0027rv_nb_transits\u0027, ShortType(), True), # Number of transits used to compute the radial velocity \n    StructField(\u0027rv_nb_deblended_transits\u0027, ShortType(), True), # Number of valid transits that have undergone deblending\n    StructField(\u0027rv_visibility_periods_used\u0027, ShortType(), True), # Number of visibility periods used to estimate the radial velocity\n    StructField(\u0027rv_expected_sig_to_noise\u0027, FloatType(), True), # Expected signal to noise ratio in the combination of the spectra used to obtain the radial velocity\n    StructField(\u0027rv_renormalised_gof\u0027, FloatType(), True), # Radial velocity renormalised goodness of fit\n    StructField(\u0027rv_chisq_pvalue\u0027, FloatType(), True), # P-value for constancy based on a chi-squared criterion\n    StructField(\u0027rv_time_duration\u0027, FloatType(), True), # Time coverage of the radial velocity time series\n    StructField(\u0027rv_amplitude_robust\u0027, FloatType(), True), # Total amplitude in the radial velocity time series after outlier removal\n    StructField(\u0027rv_template_teff\u0027, FloatType(), True), # Teff of the template used to compute the radial velocity \n    StructField(\u0027rv_template_logg\u0027, FloatType(), True), # Logg of the template used to compute the radial velocity \n    StructField(\u0027rv_template_fe_h\u0027, FloatType(), True), # [Fe/H] of the template used to compute the radial velocityy\n    StructField(\u0027rv_atm_param_origin\u0027, ShortType(), True), # Origin of the atmospheric parameters associated to the template\n    StructField(\u0027vbroad\u0027, FloatType(), True), # Spectral line broadening parameter\n    StructField(\u0027vbroad_error\u0027, FloatType(), True), # Uncertainty on the spectral line broadening\n    StructField(\u0027vbroad_nb_transits\u0027, ShortType(), True), # Number of transits used to compute vbroad\n    StructField(\u0027grvs_mag\u0027, FloatType(), True), # Integrated Grvs magnitude\n    StructField(\u0027grvs_mag_error\u0027, FloatType(), True), # Grvs magnitude uncertainty\n    StructField(\u0027grvs_mag_nb_transits\u0027, ShortType(), True), # Number of transits used to compute Grvs\n    StructField(\u0027rvs_spec_sig_to_noise\u0027, FloatType(), True), # Signal to noise ratio in the mean RVS spectrum\n    StructField(\u0027phot_variable_flag\u0027, StringType(), True), # Photometric variability flag\n    StructField(\u0027l\u0027, DoubleType(), True), # Galactic longitude\n    StructField(\u0027b\u0027, DoubleType(), True), # Galactic latitude\n    StructField(\u0027ecl_lon\u0027, DoubleType(), True), # Ecliptic longitude\n    StructField(\u0027ecl_lat\u0027, DoubleType(), True), # Ecliptic latitude\n    StructField(\u0027in_qso_candidates\u0027, BooleanType(), True), # Flag indicating the availability of additional information in the QsoCandidates table\n    StructField(\u0027in_galaxy_candidates\u0027, BooleanType(), True), # Flag indicating the availability of additional information in the GalaxyCandidates table\n    StructField(\u0027non_single_star\u0027, ShortType(), True), # Flag indicating the availability of additional information in the various Non-Single Star tables\n    StructField(\u0027has_xp_continuous\u0027, BooleanType(), True), # Flag indicating the availability of mean BP/RP spectrum in continuous representation for this source\n    StructField(\u0027has_xp_sampled\u0027, BooleanType(), True), # Flag indicating the availability of mean BP/RP spectrum in sampled form for this source\n    StructField(\u0027has_rvs\u0027, BooleanType(), True), # Flag indicating the availability of mean RVS spectrum for this source\n    StructField(\u0027has_epoch_photometry\u0027, BooleanType(), True), # Flag indicating the availability of epoch photometry for this source\n    StructField(\u0027has_epoch_rv\u0027, BooleanType(), True), # Flag indicating the availability of epoch radial velocity for this source\n    StructField(\u0027has_mcmc_gspphot\u0027, BooleanType(), True), # Flag indicating the availability of GSP-Phot MCMC samples for this source\n    StructField(\u0027has_mcmc_msc\u0027, BooleanType(), True), # Flag indicating the availability of MSC MCMC samples for this source\n    StructField(\u0027in_andromeda_survey\u0027, BooleanType(), True), # Flag indicating that the source is present in the Gaia Andromeda Photometric Survey (GAPS)\n    StructField(\u0027classprob_dsc_combmod_quasar\u0027, FloatType(), True), # Probability from DSC-Combmod of being a quasar (data used: BP/RP spectrum, photometry, astrometry)\n    StructField(\u0027classprob_dsc_combmod_galaxy\u0027, FloatType(), True), # Probability from DSC-Combmod of being a galaxy (data used: BP/RP spectrum, photometry, astrometry)\n    StructField(\u0027classprob_dsc_combmod_star\u0027, FloatType(), True), # Probability from DSC-Combmod of being a single star (but not a white dwarf) (data used: BP/RP spectrum, photometry, astrometry)\n    StructField(\u0027teff_gspphot\u0027, FloatType(), True), # Effective temperature from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027teff_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of effective temperature from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027teff_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of effective temperature from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027logg_gspphot\u0027, FloatType(), True), # Surface gravity from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027logg_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of surface gravity from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027logg_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of surface gravity from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027mh_gspphot\u0027, FloatType(), True), # Iron abundance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027mh_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of iron abundance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027mh_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of iron abundance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027distance_gspphot\u0027, FloatType(), True), # Distance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027distance_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of distance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027distance_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of distance from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027azero_gspphot\u0027, FloatType(), True), # Monochromatic extinction $A_0$ at 547.7nm from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027azero_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of monochromatic extinction $A_0$ at 547.7nm from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027azero_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of monochromatic extinction $A_0$ at 547.7nm from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ag_gspphot\u0027, FloatType(), True), # Extinction in G band from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ag_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of extinction in G band from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ag_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of extinction in G band from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ebpminrp_gspphot\u0027, FloatType(), True), # Reddening $E(G_{\\rm BP} - G_{\\rm RP})$ from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ebpminrp_gspphot_lower\u0027, FloatType(), True), # Lower confidence level (16%) of reddening  $E(G_{\\rm BP} - G_{\\rm RP})$ from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027ebpminrp_gspphot_upper\u0027, FloatType(), True), # Upper confidence level (84%) of reddening  $E(G_{\\rm BP} - G_{\\rm RP})$ from GSP-Phot Aeneas best library using BP/RP spectra\n    StructField(\u0027libname_gspphot\u0027, StringType(), True), # Name of library that achieves the highest mean log-posterior in MCMC samples and was used to derive GSP-Phot parameters in this table\n])\n\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_879578351",
      "id": "paragraph_1656060977057_2031795623",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "gaiadr3.gaia_source",
      "text": "%pyspark\n\n# read the csv files \ngdr3_gaia_source_df \u003d sqlContext.read.option(\u0027mode\u0027,\u0027failfast\u0027).option(\u0027comment\u0027, \u0027#\u0027).option(\u0027header\u0027,\u0027true\u0027).option(\u0027nullValue\u0027,\u0027null\u0027).schema(gaia_source_schema_test).csv(\u0027file:////user/nch/CSV/GDR3/cdn.gea.esac.esa.int/Gaia/gdr3/gaia_source/*.csv\u0027)\n\n# sanity check\n#gdr3_gaia_source_df.show()\n#gdr3_gaia_source_df.count()\n\n# write out to partitioned, bucketed parquet\n#gaiadmpstore.\nsaveToBinnedParquet(gdr3_gaia_source_df, outputParquetPath \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_GAIASOURCE/\u0027, name \u003d \u0027gaia_source\u0027)\n# benchmarks on standard system:\n#  10% data :  14m 44s\n# 100%      : 1h 54m 42s once /var/hadoop/data mounted on a v. high capacity Cinder volume (zombified under default config!) and 2x bigger machine.\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_794271816",
      "id": "paragraph_1656061085278_841822510",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "Reattach and read gaiadr3.gaia_source",
      "text": "%pyspark\n\n#gaiadmpstore.\nreattachParquetFileResourceToSparkContext(table_name \u003d \u0027gaia_source\u0027, file_path \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_GAIASOURCE\u0027, schema_structures \u003d (gaia_source_schema_test,))\n# ... replaces csv-backed table resource with the parquet one in the system catalogue \n\n# DF backed by the parquet file set\npdf \u003d spark.sql(\u0027select * from gaia_source\u0027)\npdf.show()\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_779472740",
      "id": "paragraph_1656062500304_1816008384",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\npdf.count()\n\n# 25th June 2020",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "1811709771\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_262164330",
      "id": "paragraph_1656075742473_252172869",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "gaiadr3.xp_continuous_mean_spectrum",
      "text": "%pyspark\n\n# uncomment as necessary\n#spark.sql(\u0027DROP TABLE xp_continuous_mean_spectrum\u0027)\n\nxp_continuous_mean_spectrum_schema \u003d StructType([\n    StructField(\u0027source_id\u0027, LongType(), False), # Unique source identifier (unique within a particular Data Release)\n    StructField(\u0027solution_id\u0027, LongType(), True), # Solution Identifier\n    StructField(\u0027bp_basis_function_id\u0027, ShortType(), True), # Identifier defining the set of basis functions for the BP spectrum representation\n    StructField(\u0027bp_degrees_of_freedom\u0027, ShortType(), True), # Degrees of freedom for the BP spectrum representation\n    StructField(\u0027bp_n_parameters\u0027, ByteType(), True), # Number of parameters for the BP spectrum representation\n    StructField(\u0027bp_n_measurements\u0027, ShortType(), True), # Number of measurements used for the BP spectrum generation\n    StructField(\u0027bp_n_rejected_measurements\u0027, ShortType(), True), # Number of rejected measurements in the BP spectrum generation\n    StructField(\u0027bp_standard_deviation\u0027, FloatType(), True), # Standard deviation for the BP spectrum representation\n    StructField(\u0027bp_chi_squared\u0027, FloatType(), True), # Chi squared for the BP spectrum representation\n    StructField(\u0027bp_coefficients\u0027, ArrayType(DoubleType()), True), # Basis function coefficients for the BP spectrum representation\n    StructField(\u0027bp_coefficient_errors\u0027, ArrayType(FloatType()), True), # Basis function coefficient errors for the BP spectrum representation\n    StructField(\u0027bp_coefficient_correlations\u0027, ArrayType(FloatType()), True), # Correlation matrix for BP coefficients\n    StructField(\u0027bp_n_relevant_bases\u0027, ShortType(), True), # Number of bases that are relevant for the representation of this mean BP spectrum\n    StructField(\u0027bp_relative_shrinking\u0027, FloatType(), True), # Measure of the relative shrinking of the coefficient vector when truncation is applied for the mean BP spectrum\n    StructField(\u0027rp_basis_function_id\u0027, ShortType(), True), # Identifier defining the set of basis functions for the BP spectrum representation\n    StructField(\u0027rp_degrees_of_freedom\u0027, ShortType(), True), # Degrees of freedom for the RP spectrum representation\n    StructField(\u0027rp_n_parameters\u0027, ByteType(), True), # Number of parameters for the RP spectrum representation\n    StructField(\u0027rp_n_measurements\u0027, ShortType(), True), # Number of measurements used for the RP spectrum generation\n    StructField(\u0027rp_n_rejected_measurements\u0027, ShortType(), True), # Number of rejected measurements in the RP spectrum generation\n    StructField(\u0027rp_standard_deviation\u0027, FloatType(), True), # Standard deviation for the RP spectrum representation\n    StructField(\u0027rp_chi_squared\u0027, FloatType(), True), # Chi squared for the RP spectrum representation\n    StructField(\u0027rp_coefficients\u0027, ArrayType(DoubleType()), True), # Basis function coefficients for the RP spectrum representation\n    StructField(\u0027rp_coefficient_errors\u0027, ArrayType(FloatType()), True), # Basis function coefficient errors for the RP spectrum representation\n    StructField(\u0027rp_coefficient_correlations\u0027, ArrayType(FloatType()), True), # Correlation matrix for RP coefficients\n    StructField(\u0027rp_n_relevant_bases\u0027, ShortType(), True), # Number of bases that are relevant for the representation of this mean RP spectrum\n    StructField(\u0027rp_relative_shrinking\u0027, FloatType(), True), # Measure of the relative shrinking of the coefficient vector when truncation is applied for the mean RP spectrum\n])\n\n# interim structure for the above with strings for the arrays\ninterim_schema \u003d create_interim_schema_for_csv(xp_continuous_mean_spectrum_schema)\n\n# read the csv files against the interim schema\ngdr3_xp_cms_schema_df \u003d sqlContext.read.option(\u0027mode\u0027,\u0027failfast\u0027).option(\u0027comment\u0027, \u0027#\u0027).option(\u0027header\u0027,\u0027true\u0027).option(\u0027nullValue\u0027,\u0027null\u0027).schema(interim_schema).csv(\u0027file:////user/nch/CSV/GDR3/cdn.gea.esac.esa.int/Gaia/gdr3/Spectroscopy/xp_continuous_mean_spectrum/*.csv\u0027)\n\n# cast the string arrays to arrays of numeric types\nrecast_df \u003d cast_all_arrays(gdr3_xp_cms_schema_df, xp_continuous_mean_spectrum_schema)\n\n# write out to partitioned, bucketed parquet\n#gaiadmpstore.\nsaveToBinnedParquet(recast_df, outputParquetPath \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_XP_CONTINUOUS_MEAN_SPECTRUM/\u0027, name \u003d \u0027xp_continuous_mean_spectrum\u0027)\n\n# benchmark 1: Took 10 hrs 28 min 19 sec; 29 June 2022 07:12:07 AM N.B. BUGGY: strings not cast to numeric; partitions \u003e 2G resulting in shuffle errors on write?\n#           2:      13 hrs 40 min 04 sec; 01 July 2022 05:51:11 AM (1.4G partitions; 1 failed stage)\n\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1698991701",
      "id": "paragraph_1656405539134_486015344",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n#gaiadmpstore.\nreattachParquetFileResourceToSparkContext(table_name \u003d \u0027xp_continuous_mean_spectrum_test\u0027, file_path \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_XP_CONTINUOUS_MEAN_SPECTRUM/\u0027, schema_structures \u003d (xp_continuous_mean_spectrum_schema,))\n# ... replaces csv-backed table resource with the parquet one in the system catalogue \n\n# DF backed by the parquet file set\npdf \u003d spark.sql(\u0027select * from xp_continuous_mean_spectrum_test\u0027)\npdf.show()\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_831425666",
      "id": "paragraph_1656412838994_787080691",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nfor line in spark.catalog.listTables(): print (line)\n\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_421876988",
      "id": "paragraph_1656491535653_1773476892",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\npdf.count()\n# ... should be 219,197,643",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "219197643\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1526252806",
      "id": "paragraph_1656491761328_1606067278",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\n# register the parquet-backed DF as an sql-queryable resource\n#sqlContext.registerDataFrameAsTable(pdf, \u0027xp_pdf_table\u0027)\n\nspark.sql(\u0027DESCRIBE EXTENDED xp_continuous_mean_spectrum_test\u0027).show(300, truncate \u003d False)",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1438197761",
      "id": "paragraph_1656491796174_79297911",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "gaiadr3.mcmc_samples_gsp_phot",
      "text": "%pyspark\n\n# uncomment as necessary\n#spark.sql(\u0027DROP TABLE mcmc_samples_gsp_phot\u0027)\n\nmcmc_samples_gsp_phot_schema \u003d StructType([\n    StructField(\u0027solution_id\u0027, LongType(), True), # Solution Identifier\n    StructField(\u0027source_id\u0027, LongType(), False), # Unique source identifier (unique within a particular Data Release)\n    StructField(\u0027nsamples\u0027, ShortType(), True), # Number of samples in the chain from GSP-Phot\n    StructField(\u0027teff\u0027, ArrayType(FloatType()), True), # MCMC samples for $T_{\\rm eff}$ from GSP-Phot\n    StructField(\u0027azero\u0027, ArrayType(FloatType()), True), # MCMC samples for extinction $A_0$ from GSP-Phot\n    StructField(\u0027logg\u0027, ArrayType(FloatType()), True), # MCMC samples for $\\log g$ from GSP-Phot\n    StructField(\u0027mh\u0027, ArrayType(FloatType()), True), # MCMC samples for the metallicity from GSP-Phot\n    StructField(\u0027ag\u0027, ArrayType(FloatType()), True), # MCMC samples for extinction in G band from GSP-Phot\n    StructField(\u0027mg\u0027, ArrayType(FloatType()), True), # MCMC samples for $M_{\\rm G}$ from GSP-Phot\n    StructField(\u0027distancepc\u0027, ArrayType(FloatType()), True), # MCMC samples for distance from GSP-Phot\n    StructField(\u0027abp\u0027, ArrayType(FloatType()), True), # MCMC samples for extinction in $G_{\\rm BP}$ band from GSP-Phot\n    StructField(\u0027arp\u0027, ArrayType(FloatType()), True), # MCMC samples for extinction in $G_{\\rm RP}$ band from GSP-Phot\n    StructField(\u0027ebpminrp\u0027, ArrayType(FloatType()), True), # MCMC samples for reddening $E(G_{\\rm BP} - G_{\\rm RP})$ from GSP-Phot\n    StructField(\u0027log_pos\u0027, ArrayType(FloatType()), True), # MCMC samples for the log-posterior from GSP-Phot\n    StructField(\u0027log_lik\u0027, ArrayType(FloatType()), True), # MCMC samples for the log-likelihood from GSP-Phot\n    StructField(\u0027radius\u0027, ArrayType(FloatType()), True), # MCMC samples for stellar radius from GSP-Phot\n])\n\n# interim structure for the above with strings for the arrays\ninterim_schema \u003d create_interim_schema_for_csv(mcmc_samples_gsp_phot_schema)\n\n# read the csv files against the interim schema\ngdr3_mcmcgsp_schema_df \u003d sqlContext.read.option(\u0027mode\u0027,\u0027failfast\u0027).option(\u0027comment\u0027, \u0027#\u0027).option(\u0027header\u0027,\u0027true\u0027).option(\u0027nullValue\u0027,\u0027null\u0027).schema(interim_schema).csv(\u0027file:////user/nch/CSV/GDR3/cdn.gea.esac.esa.int/Gaia/gdr3/Astrophysical_parameters/mcmc_samples_gsp_phot/*.csv\u0027)\n\n# cast the string arrays to arrays of numeric types\n#recast_df \u003d cast_all_arrays(gdr3_mcmcgsp_schema_df, mcmc_samples_gsp_phot_schema)\n\n# write out to partitioned, bucketed parquet\n#gaiadmpstore.\n#saveToBinnedParquet(recast_df, outputParquetPath \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_MCMC_SAMPLES_GSP_PHOT/\u0027, buckets \u003d 8192, name \u003d \u0027mcmc_samples_gsp_phot\u0027)\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_206896531",
      "id": "paragraph_1656665402966_1476353992",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "Cast",
      "text": "%pyspark\n\nrecast_df \u003d cast_all_arrays(gdr3_mcmcgsp_schema_df, mcmc_samples_gsp_phot_schema)\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1292014720",
      "id": "paragraph_1657048412401_1666241705",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "title": "Write",
      "text": "%pyspark\n\nsaveToBinnedParquet(recast_df, outputParquetPath \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_MCMC_SAMPLES_GSP_PHOT/\u0027, buckets \u003d 8192, name \u003d \u0027mcmc_samples_gsp_phot\u0027)\n\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1652986625",
      "id": "paragraph_1657048444280_1327928862",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nreattachParquetFileResourceToSparkContext(table_name \u003d \u0027mcmc_samples_gsp_phot_test\u0027, file_path \u003d \u0027file:////user/nch/PARQUET/GDR3/GDR3_MCMC_SAMPLES_GSP_PHOT/\u0027, schema_structures \u003d (mcmc_samples_gsp_phot_schema,))\n# ... replaces csv-backed table resource with the parquet one in the system catalogue \n\n# DF backed by the parquet file set\npdf \u003d spark.sql(\u0027select * from mcmc_samples_gsp_phot_test\u0027)\npdf.show()\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------------+----------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|        solution_id|       source_id|nsamples|                teff|               azero|                logg|                  mh|                  ag|                  mg|          distancepc|                 abp|                 arp|            ebpminrp|             log_pos|             log_lik|              radius|\n+-------------------+----------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|8013174454243549220|  30374008950912|     100|[3848.292, 3859.2...|[0.88284546, 0.86...|[4.8573236, 4.819...|[-0.6378278, -0.6...|[0.6155812, 0.606...|[8.844237, 8.7069...|[435.048, 465.229...|[0.8452951, 0.832...|[0.5019804, 0.494...|[0.34331465, 0.33...|[-247.89026, -245...|[-112.40377, -111...|[0.41043863, 0.43...|\n|8013174454243549221| 352221678055936|     100|[3830.0652, 3860....|[0.768318, 0.7462...|[4.725672, 4.7432...|[-0.4774369, -0.2...|[0.53499895, 0.51...|[8.501459, 8.3966...|[444.3116, 470.96...|[0.73705834, 0.71...|[0.43622565, 0.42...|[0.3008327, 0.292...|[-276.46625, -274...|[-155.22365, -156...|[0.49313825, 0.51...|\n|8013174454444875809| 801479552878976|    2000|[5628.6855, 5630....|[9.583449E-5, 0.0...|[4.3755074, 4.378...|[-0.5908031, -0.5...|[8.016164E-5, 0.0...|[4.7221828, 4.730...|[234.53506, 233.4...|[1.0073194E-4, 0....|[5.7415935E-5, 0....|[4.3316002E-5, 0....|[-798.6798, -799....|[-794.43695, -795...|[1.0367373, 1.031...|\n|8013174454444875809| 876521221326336|     100|[4699.727, 4730.2...|[0.28076276, 0.31...|[4.4528418, 4.437...|[-0.6521959, -0.5...|[0.2191461, 0.243...|[6.095134, 5.9716...|[822.4868, 861.72...|[0.2831655, 0.314...|[0.16568553, 0.18...|[0.11747998, 0.13...|[-227.508, -227.6...|[-165.61525, -160...|[0.84784687, 0.88...|\n|8013174454444875809| 970804343391360|     100|[4981.288, 4978.0...|[0.0058813784, 0....|[4.2883506, 4.286...|[-0.99700356, -0....|[0.0047420976, 8....|[5.212468, 5.2073...|[803.6928, 806.99...|[0.0060584354, 0....|[0.0034923307, 5....|[0.0025661048, 4....|[-322.7687, -322....|[-296.19046, -295...|[1.0989091, 1.103...|\n|8013174454444875809|1261144132759296|     100|[5547.7974, 5572....|[0.344016, 0.3517...|[4.5164065, 4.492...|[-0.4289122, -0.3...|[0.28206173, 0.28...|[5.369302, 5.2713...|[770.8664, 800.91...|[0.35676762, 0.36...|[0.20545734, 0.21...|[0.15131028, 0.15...|[-652.30334, -652...|[-582.24207, -579...|[0.79068923, 0.81...|\n|8013174454243549219|1267187151532544|     100|[3394.4812, 3437....|[0.18575498, 0.25...|[4.3958035, 4.438...|[-1.150762, -1.08...|[0.12653303, 0.17...|[9.8037815, 9.643...|[534.9406, 565.67...|[0.17551136, 0.23...|[0.104466334, 0.1...|[0.071045026, 0.0...|[-241.8857, -240....|[-194.1187, -184....|[0.37709025, 0.39...|\n|8013174454444875809|1301929142132608|    2000|[4242.7847, 4247....|[0.18666974, 0.19...|[1.8417175, 1.827...|[-0.2850592, -0.2...|[0.13880962, 0.14...|[0.15922993, 0.16...|[231.74431, 233.0...|[0.1818699, 0.190...|[0.10897165, 0.11...|[0.07289825, 0.07...|[-3420.0947, -342...|[-3390.3098, -339...|[18.720406, 18.81...|\n|8013174454444875809|1492694409511040|    2000|[6401.7715, 6452....|[0.104237035, 0.1...|[3.8779714, 3.936...|[-0.1742741, -0.1...|[0.09054686, 0.11...|[2.2473564, 2.430...|[523.0105, 475.75...|[0.11175714, 0.14...|[0.06297246, 0.08...|[0.048784673, 0.0...|[-779.44574, -778...|[-751.83435, -748...|[2.4543116, 2.221...|\n|8013174454243549220|1554026542528640|     100|[4414.7007, 4385....|[7.018257E-4, 2.0...|[4.8021584, 4.706...|[-1.3322544, -1.4...|[5.3711346E-4, 1....|[7.814924, 7.5954...|[955.9163, 1058.7...|[7.00873E-4, 1.99...|[4.12136E-4, 1.17...|[2.8873698E-4, 8....|[-139.10349, -137...|[-113.213326, -10...|[0.449973, 0.5068...|\n|8013174454243549221|1781488010445312|     100|[3605.3206, 3601....|[0.009776995, 0.0...|[4.1008873, 4.067...|[-1.0198402, -1.0...|[0.0068702134, 0....|[7.8153505, 7.783...|[772.8885, 781.70...|[0.009339772, 0.0...|[0.005582711, 0.0...|[0.003757061, 0.0...|[-165.1485, -166....|[-132.94505, -132...|[0.79306203, 0.80...|\n|8013174454243549220|1788256878923136|     100|[5222.321, 5220.0...|[0.005240268, 0.0...|[4.740579, 4.7104...|[-1.2085639, -1.2...|[0.0042700046, 0....|[6.413826, 6.3821...|[1981.6594, 2006....|[0.0054285876, 0....|[0.0031214585, 0....|[0.002307129, 0.0...|[-227.30603, -229...|[-159.67802, -161...|[0.56537646, 0.57...|\n|8013174454243549219|2190845638060928|     100|[3750.3054, 3715....|[0.11938478, 0.11...|[4.486806, 4.4275...|[-1.1994112, -1.3...|[0.08472779, 0.08...|[8.538671, 8.7491...|[897.65314, 819.2...|[0.115147695, 0.1...|[0.06833479, 0.06...|[0.046812907, 0.0...|[-202.79749, -195...|[-160.38518, -157...|[0.5025415, 0.467...|\n|8013174454243549221|2344060006796800|    2000|[5713.8228, 5674....|[0.023640009, 0.0...|[4.719341, 4.6844...|[-2.3423293, -2.1...|[0.019935397, 0.0...|[5.900753, 5.8866...|[1754.4967, 1780....|[0.025125159, 0.0...|[0.014148939, 0.0...|[0.01097622, 0.00...|[-156.65656, -152...|[-91.606094, -90....|[0.5991642, 0.610...|\n|8013174454243549221|2620484101978496|     100|[3642.663, 3646.2...|[0.05533566, 0.06...|[4.2454214, 4.230...|[-0.7828691, -0.7...|[0.038876172, 0.0...|[7.8076544, 7.744...|[607.8749, 624.66...|[0.05301352, 0.06...|[0.031534716, 0.0...|[0.021478802, 0.0...|[-234.66406, -235...|[-211.01279, -208...|[0.7786495, 0.800...|\n|8013174454243549220|2906387189670272|     100|[5211.08, 5217.76...|[0.00997279, 0.00...|[4.769329, 4.7685...|[-1.362025, -1.41...|[0.008158967, 0.0...|[6.518419, 6.5142...|[1980.3251, 1989....|[0.010372552, 0.0...|[0.0059393896, 0....|[0.0044331625, 8....|[-169.1655, -167....|[-95.55411, -95.4...|[0.5421622, 0.541...|\n|8013174454243549221|3546994447017856|     100|[4154.9863, 4156....|[1.1888694, 1.172...|[4.559634, 4.5568...|[0.40605184, 0.44...|[0.8384622, 0.826...|[7.1712375, 7.160...|[538.0883, 544.35...|[1.1429746, 1.127...|[0.67911816, 0.66...|[0.46385646, 0.45...|[-334.78052, -335...|[-161.56248, -163...|[0.75300145, 0.75...|\n|8013174454243549221|3582552480867200|     100|[3879.2903, 3920....|[0.2590309, 0.343...|[4.7756147, 4.809...|[-0.65016246, -0....|[0.18575239, 0.24...|[8.584705, 8.5516...|[601.931, 595.152...|[0.2495614, 0.331...|[0.14919123, 0.19...|[0.10037017, 0.13...|[-204.20233, -205...|[-152.87265, -143...|[0.4525691, 0.446...|\n|8013174454243549220|3721675061361408|     100|[4808.1104, 4809....|[0.005881653, 0.0...|[4.8919096, 4.910...|[-2.6703029, -2.4...|[0.004668942, 0.0...|[7.5128336, 7.541...|[1219.833, 1204.1...|[0.0060271868, 0....|[0.003476989, 0.0...|[0.0025501978, 9....|[-184.19064, -184...|[-140.31026, -141...|[0.4156935, 0.409...|\n|8013174454243549221|4288060988959488|     100|[4081.3008, 4169....|[0.03590246, 0.12...|[4.3682714, 4.461...|[-0.4783128, -0.3...|[0.026420848, 0.0...|[6.8042097, 6.927...|[1246.0781, 1129....|[0.034982294, 0.1...|[0.02087076, 0.07...|[0.014111534, 0.0...|[-194.45488, -200...|[-145.47003, -143...|[0.90810275, 0.81...|\n+-------------------+----------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_1070485061",
      "id": "paragraph_1656669276538_2096587573",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n\nspark.sql(\u0027DESCRIBE EXTENDED mcmc_samples_gsp_phot_test\u0027).show(300, truncate \u003d False)",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.039",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------------------+--------------------------------------------------------+-------+\n|col_name                    |data_type                                               |comment|\n+----------------------------+--------------------------------------------------------+-------+\n|solution_id                 |bigint                                                  |null   |\n|source_id                   |bigint                                                  |null   |\n|nsamples                    |smallint                                                |null   |\n|teff                        |array\u003cfloat\u003e                                            |null   |\n|azero                       |array\u003cfloat\u003e                                            |null   |\n|logg                        |array\u003cfloat\u003e                                            |null   |\n|mh                          |array\u003cfloat\u003e                                            |null   |\n|ag                          |array\u003cfloat\u003e                                            |null   |\n|mg                          |array\u003cfloat\u003e                                            |null   |\n|distancepc                  |array\u003cfloat\u003e                                            |null   |\n|abp                         |array\u003cfloat\u003e                                            |null   |\n|arp                         |array\u003cfloat\u003e                                            |null   |\n|ebpminrp                    |array\u003cfloat\u003e                                            |null   |\n|log_pos                     |array\u003cfloat\u003e                                            |null   |\n|log_lik                     |array\u003cfloat\u003e                                            |null   |\n|radius                      |array\u003cfloat\u003e                                            |null   |\n|                            |                                                        |       |\n|# Detailed Table Information|                                                        |       |\n|Database                    |gaiadr3                                                 |       |\n|Table                       |mcmc_samples_gsp_phot_test                              |       |\n|Created Time                |Fri Jul 01 10:44:50 UTC 2022                            |       |\n|Last Access                 |UNKNOWN                                                 |       |\n|Created By                  |Spark 3.1.2                                             |       |\n|Type                        |EXTERNAL                                                |       |\n|Provider                    |parquet                                                 |       |\n|Num Buckets                 |2048                                                    |       |\n|Bucket Columns              |[`source_id`]                                           |       |\n|Sort Columns                |[`source_id`]                                           |       |\n|Location                    |file:///user/nch/PARQUET/GDR3/GDR3_MCMC_SAMPLES_GSP_PHOT|       |\n+----------------------------+--------------------------------------------------------+-------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161039_400060724",
      "id": "paragraph_1656672290838_997263212",
      "dateCreated": "2022-07-10 09:09:21.039",
      "status": "READY"
    },
    {
      "text": "%pyspark\n",
      "user": "nch",
      "dateUpdated": "2022-07-10 09:09:21.040",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1657444161040_144976812",
      "id": "paragraph_1656672336040_1107723693",
      "dateCreated": "2022-07-10 09:09:21.040",
      "status": "READY"
    }
  ],
  "name": "DR3 ingests",
  "id": "2H9DKNRQ5",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}